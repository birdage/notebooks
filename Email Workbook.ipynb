{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey Chris,\n",
      "\n",
      "Do you know if the sampling rate that is reported by the platform/glider is accurate? For example if we start sampling\n",
      "at $t_0$ and have an indicated sampling frequency $f$ Hz and we receive an arbitrary sample at $t_n$ which is exactly\n",
      "$n$ seconds after $t_0$ can I make a safe assertion that it is the $\\frac{n}{f}$th sample? There is bound to be a physical error,\n",
      "is the error between the physically produced sample (with the timestamp from the instrument clock) reported in any\n",
      "documentation?  For the solution that we're thinking of the error needs to be really really small.\n",
      "\n",
      "$$\\begin{equation}\n",
      "\\varepsilon = \\left| T_n - t_n \\right|\n",
      "\\end{equation}\n",
      "$$\n",
      "\n",
      "Where $T_n$ is the observed time by the instrument clock and $t_n$ is the true time.\n",
      "\n",
      "Thanks,\n",
      "<hr />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey Chris,\n",
      "\n",
      "So the model we want to explore operates on the premise that we can determine an arbitrary sample's domain index.\n",
      "\n",
      "$$i = \\frac{t_n - t_0}{f}$$\n",
      "\n",
      "Where $i$ is the domain index, $t_n$ is the observed timestamp, $t_0$ is the start time (epoch) and $f$ is the sampling \n",
      "rate indicated by the instrument. The really important (and limiting) property is that \n",
      "$i \\in \\mathbb{Z^+}$ but $t,f \\in \\mathbb{R}$. And typically, $t$ and $f$ are represented computationally as IEEE\n",
      "floating point numbers which have a measurable $\\varepsilon_{float}$.\n",
      "\n",
      "![img](https://docs.google.com/drawings/d/1vz-uOusdHCSKCM69np1em11-0SeR7lf7b2JVsQO8r1c/pub?w=698&amp;h=475)\n",
      "\n",
      "\n",
      "It's an elegant model that would allow us to solve several issues with messages arriving out of order, or duplicate\n",
      "messages. The largest problem I see with this approach is that if at any point $\\varepsilon \\ge f$ then a data point\n",
      "will end up in the wrong position in the dataset. The worst part is that if $\\varepsilon$ is heteroscedastic, which would\n",
      "be attributed to a slowly shifting clock, then the probability of corruption is directly related to the variability of \n",
      "$\\varepsilon$.\n",
      "\n",
      "If I can get my hands on some instrument documentation that describes clock shifting characteristics as well as sampling\n",
      "frequency deviations during normal operations then I can determine the probability of an error occuring in the dataset,\n",
      "which I feel would be good information for the stake holders. \n",
      "\n",
      "\n",
      "Thanks,\n",
      "<hr />\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey Guys,\n",
      "\n",
      "I just want to check my assumptions here.\n",
      "\n",
      "#### OOI QC Functions\n",
      "\n",
      " - Global Range Test (GLBLRNG)\n",
      " - Local Range Test (LOCLRNG)\n",
      " - Spike Test (SPKETST)\n",
      " - Trend Test (TRNDTST)\n",
      " - Stuck Value Test (STUCKVL)\n",
      " - Gradient Test (GRADTST)\n",
      " - Combined Flags (CMBNFLG)\n",
      "\n",
      "Are these all of the QC functions?\n",
      "\n",
      "#### OOI Non-QC Functions\n",
      "\n",
      " - Modulus (MODULUS)\n",
      " - 1-D Interpolation (INTERP1d)\n",
      " - Polynomial Evaluation (POLYVAL)\n",
      " - Solar Elevation (SOLAREL)\n",
      "\n",
      "The above got roped into QC functions but they don't fit the Cyber Infrasctructure Quality Control definition where the\n",
      "output is a binary indicator that the input failed to meet a certain criteria set. These functions produce discrete\n",
      "value sets, do not use look up tables (except for maybe solar elevation) and more closely resemble a data transform than\n",
      "a quality control function.\n",
      "\n",
      "\n",
      "Thanks,\n",
      "<hr />\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yeah sorry it should be\n",
      "\n",
      "$$\\lambda = \\frac{1}{f}\\\\\n",
      "i = \\frac{(t_n - t_0)}{\\lambda}$$\n",
      "\n",
      "Where $\\lambda$ is the period in seconds, $f$ is the frequency in Hz, $t$ is the timestamp measured in seconds and $i$ is the domain index.\n",
      "\n",
      "And in the context of $\\varepsilon$ it was heteroscedastic not _heterscedastic_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey Tim,\n",
      "\n",
      "I was looking at milestone for data calibration management [M086](https://confluence.oceanobservatories.org/display/CIDev/M086+Data+Calibration+Management). \n",
      "Can we get some feedback from the manufacturers or subject matter experts about the calibration coefficients, I have\n",
      "only seen examples from the Seabirds. I would like to assemble a list of all the data types for these values so that we\n",
      "can narrow the scope of work for this milestone, supporting an arbitrary number of dimensions and an arbitrary data\n",
      "format would extend the scope of work far beyond what may be actually required.\n",
      "\n",
      "The most desirable outcome would be to get at least one sample value for every calibration coefficent for each\n",
      "instrument but I don't think we can reasonably expect that. Instead could we determine the shape and data types for all\n",
      "calibration coefficients for instruments we intend to support?\n",
      "\n",
      "Thanks,\n",
      "\n",
      "<hr />\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey Matthias,\n",
      "\n",
      "Do you have any documentation, confluence pages or Data Product Specifications that describe in detail the desired\n",
      "outcome for interactive QC managemnt? I'm trying to get as many resources together to identify and define the scope of\n",
      "work for the interactive qc workflow milestone for CI.\n",
      "\n",
      "So far, what I have is [CONF:Data flow during QC - Lankhorst](https://confluence.oceanobservatories.org/display/science/Data+flow+during+QC+-+Lankhorst)\n",
      "\n",
      "\n",
      "My proposed workflow is something like:\n",
      "\n",
      "1. User downloads data product from CI interface (web, IPython notebook or DAP).\n",
      "2. The user inspects the data in the user's environment and determines a subset of data to apply a set of QC values to.\n",
      "3. The user initiates a QC feedback interface in the CI web interface\n",
      "    1. The user selects the applicable domain of application for the QC values\n",
      "    2. The user attaches a file that contains the QC value set\n",
      "    3. The user provides additional descriptive metadata describing methodology, provenance and authority.\n",
      "4. CI adds a new parameter to the data product that describes the user uploaded QC value set.\n",
      "5. The data product is now presented including the user uploaded QC value set, for all domain values where the user QC\n",
      "   value set does not contain a value, a fill value is applied.\n",
      "\n",
      "Does that sound about right?\n",
      "\n",
      "Thanks,\n",
      "<hr />\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}